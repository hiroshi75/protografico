# Prompt Optimization Priorities

A priority guide for applying optimization techniques in order of improvement impact.

## üìä Optimization Priorities

In order of improvement impact:

### 1. Adding Few-Shot Examples (High Impact, Low Cost)
- **Improvement**: Accuracy +10-20%
- **Cost**: +5-10% (increased input tokens)
- **Implementation Time**: 30 minutes - 1 hour
- **Recommended**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

### 2. Output Format Structuring (High Impact, Low Cost)
- **Improvement**: Latency -10-20%, Parsing errors -90%
- **Cost**: ¬±0%
- **Implementation Time**: 15-30 minutes
- **Recommended**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

### 3. Temperature/Max Tokens Adjustment (Medium Impact, Zero Cost)
- **Improvement**: Latency -10-30%, Cost -20-40%
- **Cost**: Reduction
- **Implementation Time**: 10-15 minutes
- **Recommended**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

### 4. Clear Instructions and Guidelines (Medium Impact, Low Cost)
- **Improvement**: Accuracy +5-10%, Quality +15-25%
- **Cost**: +2-5%
- **Implementation Time**: 30 minutes - 1 hour
- **Recommended**: ‚≠ê‚≠ê‚≠ê‚≠ê

### 5. Model Selection Optimization (High Impact, Requires Validation)
- **Improvement**: Cost -40-60%
- **Risk**: Accuracy -2-5%
- **Implementation Time**: 2-4 hours (including validation)
- **Recommended**: ‚≠ê‚≠ê‚≠ê‚≠ê

### 6. Prompt Caching (High Impact, Medium Cost)
- **Improvement**: Cost -50-90% (on cache hit)
- **Complexity**: Medium (implementation and monitoring)
- **Implementation Time**: 1-2 hours
- **Recommended**: ‚≠ê‚≠ê‚≠ê‚≠ê

### 7. Chain-of-Thought (High Impact for Specific Tasks)
- **Improvement**: Accuracy +15-30% for complex tasks
- **Cost**: +20-40%
- **Implementation Time**: 1-2 hours
- **Recommended**: ‚≠ê‚≠ê‚≠ê (complex tasks only)

### 8. Self-Consistency (Limited Use)
- **Improvement**: Accuracy +10-20%
- **Cost**: +200-300%
- **Implementation Time**: 2-3 hours
- **Recommended**: ‚≠ê‚≠ê (critical decisions only)

## üîÑ Iterative Optimization Process

```
1. Measure baseline
   ‚Üì
2. Select the most impactful improvement
   ‚Üì
3. Implement (one change only)
   ‚Üì
4. Evaluate (with same test cases)
   ‚Üì
5. Is improvement confirmed?
   ‚îú‚îÄ Yes ‚Üí Keep change, go to step 2
   ‚îî‚îÄ No ‚Üí Rollback change, try different improvement
   ‚Üì
6. Goal achieved?
   ‚îú‚îÄ Yes ‚Üí Complete
   ‚îî‚îÄ No ‚Üí Go to step 2
```

## Summary

For effective prompt optimization:

1. ‚úÖ **Clarity**: Clear role, task, and output format
2. ‚úÖ **Few-Shot Examples**: 3-7 high-quality examples
3. ‚úÖ **Structuring**: Structured output like JSON
4. ‚úÖ **Parameter Tuning**: Task-appropriate temperature/max_tokens
5. ‚úÖ **Incremental Improvement**: One change at a time, measure, validate
6. ‚úÖ **Cost-Conscious**: Model selection, caching, max_tokens
7. ‚úÖ **Measurement-Driven**: Evaluate all changes quantitatively
